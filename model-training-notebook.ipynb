{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCARPd4qdeF2",
        "outputId": "8b88cbbb-9f29-43b0-976b-633c90a2d307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-23 23:48:18--  https://huggingface.co/datasets/barryallen16/Sarav-real-fake-automobile-parts-dataset/resolve/main/dataset_clean.zip\n",
            "Resolving huggingface.co (huggingface.co)... 108.138.246.79, 108.138.246.71, 108.138.246.67, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.138.246.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/68dc24c5ee15b4bd54002f0b/0bed99891ab2dcf6c4186bf54c7c4dbbf9af51a86d2b1e56f33ec4a49e8872dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251023T234818Z&X-Amz-Expires=3600&X-Amz-Signature=6f496c5d97435c72ed1d7d7d665bc7005e5fdce9a12bfbc760abe07f5037b468&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27dataset_clean.zip%3B+filename%3D%22dataset_clean.zip%22%3B&response-content-type=application%2Fzip&x-id=GetObject&Expires=1761266898&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MTI2Njg5OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGRjMjRjNWVlMTViNGJkNTQwMDJmMGIvMGJlZDk5ODkxYWIyZGNmNmM0MTg2YmY1NGM3YzRkYmJmOWFmNTFhODZkMmIxZTU2ZjMzZWM0YTQ5ZTg4NzJkYyoifV19&Signature=ED-O%7EZS0tlexDBH0pzMR7XGDr72AUkCaOx-PGfQCgEy07u5qNVy3g1XGFLdIp1jum-T6qU6vMvbf1z4cRZXGMqisVGQ0BgPmgFHXYgDIxh5Wx9-dv6ntNnbUC5kVHABH9QPFITnMJNjqHZgGNMaJ9AYQIykYM20MlhDvJ005ExgrIJYVL4INMpAnDCyu%7EwxMIQC9R3N43-dEyCmathYWhXLlL19pHfJHLHKNygA0dqgplfq%7EHxQRKNZnrfIU7vSxhfv9F3GbAv025hu9qq3C9SckBJW0fJmSJarBj8S5LRZxPC4wP6dHtdJQjQziIHHgb4ik4oMeDD64trIoKsYzcA__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
            "--2025-10-23 23:48:18--  https://cas-bridge.xethub.hf.co/xet-bridge-us/68dc24c5ee15b4bd54002f0b/0bed99891ab2dcf6c4186bf54c7c4dbbf9af51a86d2b1e56f33ec4a49e8872dc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251023%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251023T234818Z&X-Amz-Expires=3600&X-Amz-Signature=6f496c5d97435c72ed1d7d7d665bc7005e5fdce9a12bfbc760abe07f5037b468&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27dataset_clean.zip%3B+filename%3D%22dataset_clean.zip%22%3B&response-content-type=application%2Fzip&x-id=GetObject&Expires=1761266898&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2MTI2Njg5OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82OGRjMjRjNWVlMTViNGJkNTQwMDJmMGIvMGJlZDk5ODkxYWIyZGNmNmM0MTg2YmY1NGM3YzRkYmJmOWFmNTFhODZkMmIxZTU2ZjMzZWM0YTQ5ZTg4NzJkYyoifV19&Signature=ED-O%7EZS0tlexDBH0pzMR7XGDr72AUkCaOx-PGfQCgEy07u5qNVy3g1XGFLdIp1jum-T6qU6vMvbf1z4cRZXGMqisVGQ0BgPmgFHXYgDIxh5Wx9-dv6ntNnbUC5kVHABH9QPFITnMJNjqHZgGNMaJ9AYQIykYM20MlhDvJ005ExgrIJYVL4INMpAnDCyu%7EwxMIQC9R3N43-dEyCmathYWhXLlL19pHfJHLHKNygA0dqgplfq%7EHxQRKNZnrfIU7vSxhfv9F3GbAv025hu9qq3C9SckBJW0fJmSJarBj8S5LRZxPC4wP6dHtdJQjQziIHHgb4ik4oMeDD64trIoKsYzcA__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
            "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 99.84.215.123, 99.84.215.118, 99.84.215.77, ...\n",
            "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|99.84.215.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 42344293 (40M) [application/zip]\n",
            "Saving to: â€˜dataset_clean.zipâ€™\n",
            "\n",
            "dataset_clean.zip   100%[===================>]  40.38M  51.3MB/s    in 0.8s    \n",
            "\n",
            "2025-10-23 23:48:19 (51.3 MB/s) - â€˜dataset_clean.zipâ€™ saved [42344293/42344293]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/datasets/barryallen16/Sarav-real-fake-automobile-parts-dataset/resolve/main/dataset_clean.zip\n",
        "!unzip -q dataset_clean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8F5klOQevo6",
        "outputId": "6a76d4cd-37d5-4183-e71c-466184efee68"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.220-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.10.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.220-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.220 ultralytics-thop-2.0.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "from ultralytics import YOLO\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# ============================================================================\n",
        "# ENVIRONMENT SETUP\n",
        "# ============================================================================\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"YOLOV8 CLASSIFICATION TRAINING - COUNTERFEIT BIKE PARTS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Model selection: n=nano, s=small, m=medium, l=large, x=extra-large\n",
        "# For 443 images with counterfeit detection: medium (m) recommended\n",
        "MODEL_SIZE = 'm'  # Best balance for your dataset size\n",
        "MODEL_PATH = f'yolov8{MODEL_SIZE}-cls.pt'\n",
        "\n",
        "# Dataset configuration\n",
        "DATA_DIR = 'dataset_clean'  # Your cleaned dataset directory\n",
        "\n",
        "# Training hyperparameters (optimized for counterfeit detection)\n",
        "TRAINING_CONFIG = {\n",
        "    # Basic settings\n",
        "    'data': DATA_DIR,\n",
        "    'epochs': 150,  # Increased for better convergence[web:112][web:234]\n",
        "    'imgsz': 320,   # Higher than 224 for better detail recognition[web:112][web:237]\n",
        "    'batch': 32,    # Adjust based on GPU memory[web:112][web:239]\n",
        "    'device': 0,    # GPU device (0 for single GPU)\n",
        "\n",
        "    # Early stopping\n",
        "    'patience': 30,  # Stop if no improvement for 30 epochs[web:112][web:240]\n",
        "\n",
        "    # Optimizer settings\n",
        "    'optimizer': 'AdamW',  # Best for small datasets[web:112][web:233]\n",
        "    'lr0': 0.001,          # Initial learning rate[web:112][web:233]\n",
        "    'lrf': 0.01,           # Final learning rate (lr0 * lrf)[web:112]\n",
        "    'momentum': 0.937,     # SGD momentum/Adam beta1[web:112][web:241]\n",
        "    'weight_decay': 0.0005,  # Optimizer weight decay[web:112][web:233]\n",
        "\n",
        "    # Data augmentation for classification[web:235]\n",
        "    'auto_augment': 'randaugment',  # RandAugment for classification[web:235]\n",
        "    'hsv_h': 0.015,      # HSV-Hue augmentation (0.0-1.0)[web:112][web:235]\n",
        "    'hsv_s': 0.7,        # HSV-Saturation augmentation (0.0-1.0)[web:112]\n",
        "    'hsv_v': 0.4,        # HSV-Value augmentation (0.0-1.0)[web:112]\n",
        "    'degrees': 15.0,     # Rotation (+/- deg)[web:235][web:238]\n",
        "    'translate': 0.1,    # Translation (+/- fraction)[web:235]\n",
        "    'scale': 0.5,        # Image scale (+/- gain)[web:112][web:235]\n",
        "    'flipud': 0.5,       # Vertical flip probability[web:235][web:241]\n",
        "    'fliplr': 0.5,       # Horizontal flip probability[web:235][web:238]\n",
        "\n",
        "    # Validation settings\n",
        "    'val': True,\n",
        "    'save': True,\n",
        "    'save_period': -1,   # Save checkpoint every x epochs (-1 = disabled)\n",
        "    'cache': True,       # Cache images for faster training[web:240]\n",
        "    'workers': 8,        # Number of worker threads[web:239]\n",
        "    'verbose': True,\n",
        "\n",
        "    # Output settings\n",
        "    'project': 'bike_parts_classifier',\n",
        "    'name': f'yolov8{MODEL_SIZE}_counterfeit_detection',\n",
        "    'exist_ok': True,\n",
        "    'plots': True,       # Generate training plots[web:239]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAD-SGGteP-N",
        "outputId": "abe5262f-5c95-4aaf-a707-202cf3814e7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "================================================================================\n",
            "YOLOV8 CLASSIFICATION TRAINING - COUNTERFEIT BIKE PARTS\n",
            "================================================================================\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: Tesla T4\n",
            "CUDA memory: 14.7 GB\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_dataset_structure(data_dir):\n",
        "    \"\"\"Validate dataset structure and count images\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"DATASET VALIDATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    required_splits = ['train', 'valid']\n",
        "    class_names = []\n",
        "\n",
        "    for split in required_splits:\n",
        "        split_path = Path(data_dir) / split\n",
        "        if not split_path.exists():\n",
        "            raise ValueError(f\"Missing required directory: {split_path}\")\n",
        "\n",
        "        # Get class names from train split\n",
        "        if split == 'train':\n",
        "            class_names = sorted([d.name for d in split_path.iterdir() if d.is_dir()])\n",
        "            print(f\"\\nðŸ“‚ Detected {len(class_names)} classes:\")\n",
        "            for cls in class_names:\n",
        "                print(f\"   - {cls}\")\n",
        "\n",
        "    # Count images per split and class\n",
        "    print(f\"\\nðŸ“Š Image counts:\")\n",
        "    total_train = 0\n",
        "    total_valid = 0\n",
        "\n",
        "    for split in required_splits:\n",
        "        print(f\"\\n{split.upper()}:\")\n",
        "        split_total = 0\n",
        "        for cls in class_names:\n",
        "            cls_path = Path(data_dir) / split / cls\n",
        "            if cls_path.exists():\n",
        "                count = len(list(cls_path.glob('*.jpg'))) + len(list(cls_path.glob('*.png')))\n",
        "                split_total += count\n",
        "                print(f\"   {cls:30s}: {count:4d} images\")\n",
        "            else:\n",
        "                print(f\"   {cls:30s}: MISSING!\")\n",
        "\n",
        "        print(f\"   {'TOTAL':30s}: {split_total:4d} images\")\n",
        "        if split == 'train':\n",
        "            total_train = split_total\n",
        "        else:\n",
        "            total_valid = split_total\n",
        "\n",
        "    print(f\"\\nðŸ“Š Dataset Summary:\")\n",
        "    print(f\"   Total training images: {total_train}\")\n",
        "    print(f\"   Total validation images: {total_valid}\")\n",
        "    print(f\"   Train/Val ratio: {total_train/total_valid:.1f}:1\")\n",
        "\n",
        "    # Check class balance\n",
        "    print(f\"\\nâš–ï¸  Class Balance Check:\")\n",
        "    for cls in class_names:\n",
        "        train_count = len(list((Path(data_dir) / 'train' / cls).glob('*.[jp][pn]g')))\n",
        "        if total_train > 0:\n",
        "            percentage = train_count / total_train * 100\n",
        "            status = \"âœ…\" if 20 <= percentage <= 80 else \"âš ï¸\"\n",
        "            print(f\"   {status} {cls:30s}: {percentage:5.1f}%\")\n",
        "\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    return class_names, total_train, total_valid"
      ],
      "metadata": {
        "id": "BX8ZwxYeenpQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_counterfeit_detector():\n",
        "    \"\"\"Train YOLOv8 classification model for counterfeit detection\"\"\"\n",
        "\n",
        "    # Validate dataset\n",
        "    class_names, n_train, n_valid = validate_dataset_structure(DATA_DIR)\n",
        "\n",
        "    # Adjust batch size if dataset is small\n",
        "    if n_train < 200:\n",
        "        TRAINING_CONFIG['batch'] = 16\n",
        "        print(f\"âš ï¸  Small dataset detected. Reduced batch size to 16\\n\")\n",
        "\n",
        "    # Load pretrained model\n",
        "    print(\"=\"*80)\n",
        "    print(\"MODEL INITIALIZATION\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Loading YOLOv8{MODEL_SIZE.upper()}-cls pretrained on ImageNet...\")\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    print(f\"âœ… Model loaded successfully!\")\n",
        "    print(f\"   Parameters: {sum(p.numel() for p in model.model.parameters())/1e6:.1f}M\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    # Train model\n",
        "    print(\"=\"*80)\n",
        "    print(\"STARTING TRAINING\")\n",
        "    print(\"=\"*80)\n",
        "    print(f\"Configuration:\")\n",
        "    for key, value in TRAINING_CONFIG.items():\n",
        "        if key not in ['data']:\n",
        "            print(f\"   {key:20s}: {value}\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    try:\n",
        "        results = model.train(**TRAINING_CONFIG)\n",
        "        print(\"\\nâœ… Training completed successfully!\")\n",
        "        return results, model\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nâš ï¸  Training interrupted by user\")\n",
        "        return None, model\n",
        "    except Exception as e:\n",
        "        print(f\"\\nâŒ Training failed: {e}\")\n",
        "        raise"
      ],
      "metadata": {
        "id": "0tMAY_PKehjl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, results):\n",
        "    \"\"\"Evaluate trained model and generate reports\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"MODEL EVALUATION\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Validate on validation set\n",
        "    print(\"\\nðŸ“Š Running validation...\")\n",
        "    metrics = model.val()\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"\\nðŸ“ˆ Performance Metrics:\")\n",
        "    print(f\"   Top-1 Accuracy: {metrics.top1:.4f} ({metrics.top1*100:.2f}%)\")\n",
        "    print(f\"   Top-5 Accuracy: {metrics.top5:.4f} ({metrics.top5*100:.2f}%)\")\n",
        "\n",
        "    # Per-class accuracy\n",
        "    if hasattr(metrics, 'class_result'):\n",
        "        print(f\"\\nðŸ“Š Per-Class Performance:\")\n",
        "        class_names, _, _ = validate_dataset_structure(DATA_DIR)\n",
        "        for i, cls in enumerate(class_names):\n",
        "            if i < len(metrics.class_result):\n",
        "                print(f\"   {cls:30s}: {metrics.class_result[i]:.4f}\")\n",
        "\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "XSlriPeOefzL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_inference(model, test_images):\n",
        "    \"\"\"Run test inference on sample images\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"TEST INFERENCE\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for img_path in test_images:\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"âš ï¸  Image not found: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        results = model.predict(img_path, verbose=False)\n",
        "        result = results[0]\n",
        "\n",
        "        # Get prediction\n",
        "        top1_idx = result.probs.top1\n",
        "        top1_conf = result.probs.top1conf\n",
        "        pred_class = result.names[top1_idx]\n",
        "\n",
        "        # Get top 3 predictions\n",
        "        top3_indices = result.probs.top5[:3]\n",
        "\n",
        "        print(f\"\\nðŸ“¸ Image: {os.path.basename(img_path)}\")\n",
        "        print(f\"   ðŸŽ¯ Prediction: {pred_class}\")\n",
        "        print(f\"   ðŸ“Š Confidence: {top1_conf:.4f} ({top1_conf*100:.2f}%)\")\n",
        "        print(f\"   ðŸ“‹ Top 3 predictions:\")\n",
        "        for i, idx in enumerate(top3_indices, 1):\n",
        "            cls_name = result.names[idx]\n",
        "            conf = result.probs.data[idx]\n",
        "            print(f\"      {i}. {cls_name:30s}: {conf:.4f} ({conf*100:.2f}%)\")\n",
        "\n",
        "    print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "id": "vaGGQK6Keco-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_model(model, formats=['onnx', 'torchscript']):\n",
        "    \"\"\"Export model to deployment formats\"\"\"\n",
        "\n",
        "    print(\"=\"*80)\n",
        "    print(\"MODEL EXPORT\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    for fmt in formats:\n",
        "        try:\n",
        "            print(f\"\\nðŸ“¦ Exporting to {fmt.upper()}...\")\n",
        "            model.export(format=fmt, imgsz=320)\n",
        "            print(f\"   âœ… Successfully exported to {fmt.upper()}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   âŒ Export to {fmt.upper()} failed: {e}\")\n",
        "\n",
        "    print(\"=\"*80 + \"\\n\")"
      ],
      "metadata": {
        "id": "VS1VI0yzeW3j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results, model = train_counterfeit_detector()\n",
        "\n",
        "if results is not None:\n",
        "    # Evaluate model\n",
        "    metrics = evaluate_model(model, results)\n",
        "\n",
        "    # Test inference on sample images\n",
        "    test_images = [\n",
        "        f'{DATA_DIR}/valid/spark_plug_fake/61.jpg',\n",
        "        f'{DATA_DIR}/valid/helmet_genuine/52.jpg',\n",
        "        f'{DATA_DIR}/valid/air_filter_fake/31.jpg',\n",
        "    ]\n",
        "    test_inference(model, test_images)\n",
        "\n",
        "    # Export model\n",
        "    export_model(model, formats=['onnx'])\n",
        "\n",
        "    print(\"\\nðŸŽ‰ Training pipeline completed successfully!\")\n",
        "    print(f\"ðŸ“ Results saved to: {TRAINING_CONFIG['project']}/{TRAINING_CONFIG['name']}/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spqQxDkseUrr",
        "outputId": "bfade53f-4883-45b1-99b2-5bdbe3ddc6cb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATASET VALIDATION\n",
            "================================================================================\n",
            "\n",
            "ðŸ“‚ Detected 6 classes:\n",
            "   - air_filter_fake\n",
            "   - air_filter_genuine\n",
            "   - helmet_fake\n",
            "   - helmet_genuine\n",
            "   - spark_plug_fake\n",
            "   - spark_plug_genuine\n",
            "\n",
            "ðŸ“Š Image counts:\n",
            "\n",
            "TRAIN:\n",
            "   air_filter_fake               :   30 images\n",
            "   air_filter_genuine            :   68 images\n",
            "   helmet_fake                   :   51 images\n",
            "   helmet_genuine                :   58 images\n",
            "   spark_plug_fake               :   37 images\n",
            "   spark_plug_genuine            :   82 images\n",
            "   TOTAL                         :  326 images\n",
            "\n",
            "VALID:\n",
            "   air_filter_fake               :    3 images\n",
            "   air_filter_genuine            :   12 images\n",
            "   helmet_fake                   :   21 images\n",
            "   helmet_genuine                :   21 images\n",
            "   spark_plug_fake               :    9 images\n",
            "   spark_plug_genuine            :   23 images\n",
            "   TOTAL                         :   89 images\n",
            "\n",
            "ðŸ“Š Dataset Summary:\n",
            "   Total training images: 326\n",
            "   Total validation images: 89\n",
            "   Train/Val ratio: 3.7:1\n",
            "\n",
            "âš–ï¸  Class Balance Check:\n",
            "   âš ï¸ air_filter_fake               :   9.2%\n",
            "   âœ… air_filter_genuine            :  20.9%\n",
            "   âš ï¸ helmet_fake                   :  15.6%\n",
            "   âš ï¸ helmet_genuine                :  17.8%\n",
            "   âš ï¸ spark_plug_fake               :  11.3%\n",
            "   âœ… spark_plug_genuine            :  25.2%\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "MODEL INITIALIZATION\n",
            "================================================================================\n",
            "Loading YOLOv8M-cls pretrained on ImageNet...\n",
            "âœ… Model loaded successfully!\n",
            "   Parameters: 17.1M\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "STARTING TRAINING\n",
            "================================================================================\n",
            "Configuration:\n",
            "   epochs              : 150\n",
            "   imgsz               : 320\n",
            "   batch               : 32\n",
            "   device              : 0\n",
            "   patience            : 30\n",
            "   optimizer           : AdamW\n",
            "   lr0                 : 0.001\n",
            "   lrf                 : 0.01\n",
            "   momentum            : 0.937\n",
            "   weight_decay        : 0.0005\n",
            "   auto_augment        : randaugment\n",
            "   hsv_h               : 0.015\n",
            "   hsv_s               : 0.7\n",
            "   hsv_v               : 0.4\n",
            "   degrees             : 15.0\n",
            "   translate           : 0.1\n",
            "   scale               : 0.5\n",
            "   flipud              : 0.5\n",
            "   fliplr              : 0.5\n",
            "   val                 : True\n",
            "   save                : True\n",
            "   save_period         : -1\n",
            "   cache               : True\n",
            "   workers             : 8\n",
            "   verbose             : True\n",
            "   project             : bike_parts_classifier\n",
            "   name                : yolov8m_counterfeit_detection\n",
            "   exist_ok            : True\n",
            "   plots               : True\n",
            "================================================================================\n",
            "\n",
            "Ultralytics 8.3.220 ðŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset_clean, degrees=15.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=150, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8m_counterfeit_detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=30, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=bike_parts_classifier, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/bike_parts_classifier/yolov8m_counterfeit_detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/dataset_clean/train... found 327 images in 6 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/dataset_clean/valid... found 89 images in 6 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=6\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
            "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
            "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
            "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
            "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
            "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
            "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
            "  7                  -1  1   2655744  ultralytics.nn.modules.conv.Conv             [384, 768, 3, 2]              \n",
            "  8                  -1  2   7084032  ultralytics.nn.modules.block.C2f             [768, 768, 2, True]           \n",
            "  9                  -1  1    993286  ultralytics.nn.modules.head.Classify         [768, 6]                      \n",
            "YOLOv8m-cls summary: 80 layers, 15,780,022 parameters, 15,780,022 gradients, 41.9 GFLOPs\n",
            "Transferred 228/230 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "WARNING âš ï¸ Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.1Â±0.1 ms, read: 1247.9Â±160.5 MB/s, size: 129.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset_clean/train... 327 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 327/327 456.4Kit/s 0.0s\n",
            "WARNING âš ï¸ Classification `cache_ram` training has known memory leak in https://github.com/ultralytics/ultralytics/issues/9824, setting `cache_ram=False`.\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 553.0Â±502.4 MB/s, size: 143.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset_clean/valid... 89 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 89/89 37.1Kit/s 0.0s\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 38 weight(decay=0.0), 39 weight(decay=0.0005), 39 bias(decay=0.0)\n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/bike_parts_classifier/yolov8m_counterfeit_detection\u001b[0m\n",
            "Starting training for 150 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      1/150      2.83G       1.71         32        320: 36% â”â”â”â”â”€â”€â”€â”€â”€â”€â”€â”€ 4/11 1.6it/s 6.3s<4.3s\n",
            "\n",
            "âš ï¸  Training interrupted by user\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Test inference on sample images\n",
        "    test_images = [\n",
        "        f'{DATA_DIR}/valid/spark_plug_fake/61.jpg',\n",
        "        f'{DATA_DIR}/valid/helmet_genuine/52.jpg',\n",
        "        f'{DATA_DIR}/valid/air_filter_fake/31.jpg',\n",
        "    ]\n",
        "    test_inference(model, test_images)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2Kevxk9esa9",
        "outputId": "82c0d174-0a66-4d3c-864f-8cd747686ed4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TEST INFERENCE\n",
            "================================================================================\n",
            "\n",
            "ðŸ“¸ Image: 61.jpg\n",
            "   ðŸŽ¯ Prediction: spark_plug_genuine\n",
            "   ðŸ“Š Confidence: 0.3046 (30.46%)\n",
            "   ðŸ“‹ Top 3 predictions:\n",
            "      1. spark_plug_genuine            : 0.3046 (30.46%)\n",
            "      2. helmet_fake                   : 0.2201 (22.01%)\n",
            "      3. helmet_genuine                : 0.1808 (18.08%)\n",
            "\n",
            "ðŸ“¸ Image: 52.jpg\n",
            "   ðŸŽ¯ Prediction: helmet_fake\n",
            "   ðŸ“Š Confidence: 0.3222 (32.22%)\n",
            "   ðŸ“‹ Top 3 predictions:\n",
            "      1. helmet_fake                   : 0.3222 (32.22%)\n",
            "      2. helmet_genuine                : 0.1724 (17.24%)\n",
            "      3. air_filter_genuine            : 0.1718 (17.18%)\n",
            "\n",
            "ðŸ“¸ Image: 31.jpg\n",
            "   ðŸŽ¯ Prediction: helmet_fake\n",
            "   ðŸ“Š Confidence: 0.3314 (33.14%)\n",
            "   ðŸ“‹ Top 3 predictions:\n",
            "      1. helmet_fake                   : 0.3314 (33.14%)\n",
            "      2. air_filter_genuine            : 0.2103 (21.03%)\n",
            "      3. spark_plug_genuine            : 0.1239 (12.39%)\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r bike_parts_classifier.zip bike_parts_classifier/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHeOo0c4gzwr",
        "outputId": "d25dcd86-3ea3-485b-ebd5-344cac57581b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: bike_parts_classifier/ (stored 0%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/ (stored 0%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/confusion_matrix.png (deflated 25%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/val_batch0_pred.jpg (deflated 3%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/val_batch1_labels.jpg (deflated 4%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/train_batch1.jpg (deflated 7%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/confusion_matrix_normalized.png (deflated 23%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/train_batch0.jpg (deflated 6%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/train_batch2.jpg (deflated 8%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/val_batch0_labels.jpg (deflated 3%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/results.png (deflated 6%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/weights/ (stored 0%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/weights/best.pt (deflated 8%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/weights/last.pt (deflated 8%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/weights/best.onnx (deflated 17%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/args.yaml (deflated 52%)\n",
            "  adding: bike_parts_classifier/yolov8m_counterfeit_detection/val_batch1_pred.jpg (deflated 4%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eecd0nZmg2EJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}